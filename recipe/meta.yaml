{% set name = "pyautogen" %}
{% set version = "0.2.28" %}

package:
  name: "{{ name|lower }}"
  version: "{{ version }}"

source:
  url: "https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz"
  sha256: f74686a981f2b6046a9cf6aff5a5e61615ec60d5559a49e7474467fbdf4e077b

build:
  noarch: python
  number: 0
  script: "{{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation"

requirements:
  host:
    - diskcache
    - docker
    - flaml
    - numpy >=1.17.0,<2
    - openai >=1.3
    - packaging
    - pip
    - pydantic >=1.10,<3,!=2.6.0
    - python
    - python-dotenv
    - termcolor
    - tiktoken
    - wheel
  run:
    - diskcache
    - docker
    - flaml
    - numpy >=1.17.0,<2
    - openai >=1.3
    - packaging
    - pydantic >=1.10,<3,!=2.6.0
    - python
    - python-dotenv
    - termcolor
    - tiktoken

test:
  imports:
    - autogen
    - autogen.agentchat
    - autogen.agentchat.contrib
    - autogen.agentchat.contrib.capabilities
    - autogen.agentchat.contrib.vectordb
    - autogen.cache
    - autogen.coding
    - autogen.coding.jupyter
    - autogen.extensions
    - autogen.io
    - autogen.logger
    - autogen.oai
  commands:
    - pip check

about:
  home: "https://github.com/microsoft/autogen"
  license: MIT
  license_family: MIT
  license_file: 
  summary: "Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"
  doc_url: 
  dev_url: 

extra:
  anaconda-services:
    ref: https://anaconda.zendesk.com/agent/tickets/49522
    reason: Client request
  recipe-maintainers:
    - ianaobi
    - bkreider
